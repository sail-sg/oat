deepspeed --module oat.experiment.offline \
    --gradient-checkpointing \
    --flash-attn \
    --rnd-seed \
    --dap-algo BNF \
    --pretrain meta-llama/Meta-Llama-3-8B-Instruct \
    --apply-chat-template \
    --ref-offload \
    --zero-stage 3 \
    --beta 0.01 \
    --preference_data princeton-nlp/llama3-ultrafeedback-armorm \
    --max-train 99999 \
    --prompt_max_length 1800 \
    --generate_max_length 1000 \
    --save_steps 100 \
    --input_key prompt \
    --chosen_key chosen \
    --rejected_key rejected \
    --train_split train \
    --train_batch_size 128 \
    --use-wb \
    --wb-run-name llama3_8b_offline_dpo \
    --gpus 8

export LD_LIBRARY_PATH=~/.conda/envs/oat/lib/